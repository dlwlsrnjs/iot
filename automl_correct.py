"""
ì¤‘ë³µ ì œê±° ë° ì˜¬ë°”ë¥¸ ë°ì´í„° ë¶„í• 
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score
from flaml import AutoML
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ì¤‘ë³µ ì œê±° ë° ì˜¬ë°”ë¥¸ AutoML í•™ìŠµ")
print("=" * 80)

# =========================
# ì´ì§„ ë¶„ë¥˜
# =========================
print("\n[1] ì´ì§„ ë¶„ë¥˜ ë°ì´í„° ì²˜ë¦¬")

# ë°ì´í„° ë¡œë“œ
df_train = pd.read_csv('/home/work/skku/iot/Datasets/Farm-Flow_Train_Binary.csv')
df_test = pd.read_csv('/home/work/skku/iot/Datasets/Farm-Flow_Test_Binary.csv')

# ì „ì²´ ë°ì´í„° í•©ì¹˜ê¸°
df_all = pd.concat([df_train, df_test], ignore_index=True)
print(f"ì „ì²´ ë°ì´í„°: {df_all.shape}")

# ì¤‘ë³µ ì œê±° (íŠ¹ì§•ë§Œ ì‚¬ìš©)
feature_cols = [col for col in df_all.columns if col not in ['is_attack', 'traffic']]
df_unique = df_all.drop_duplicates(subset=feature_cols, keep='first')
print(f"ì¤‘ë³µ ì œê±° í›„: {df_unique.shape} ({len(df_unique)/len(df_all)*100:.1f}%)")

# íŠ¹ì§•ê³¼ ë¼ë²¨ ë¶„ë¦¬
X = df_unique[feature_cols].select_dtypes(include=[np.number])
y = df_unique['is_attack']

print(f"íŠ¹ì§• ìˆ˜: {X.shape[1]}")
print(f"ë¼ë²¨ ë¶„í¬:\n{y.value_counts()}")

# ìƒˆë¡œìš´ train/test ë¶„í•  (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nìƒˆë¡œìš´ ë¶„í• :")
print(f"í›ˆë ¨: {X_train.shape[0]}, í…ŒìŠ¤íŠ¸: {X_test.shape[0]}")
print(f"í›ˆë ¨ ë¼ë²¨: {y_train.value_counts().to_dict()}")
print(f"í…ŒìŠ¤íŠ¸ ë¼ë²¨: {y_test.value_counts().to_dict()}")

# ì •ê·œí™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# AutoML í•™ìŠµ
print(f"\n[2] FLAML AutoML í•™ìŠµ (5ë¶„) - GPU í™œìš© (XGBoost)")

# XGBoostë§Œ GPU ì‚¬ìš©, LightGBMì€ CPU
from flaml.automl.model import LGBMEstimator, XGBoostSklearnEstimator

automl = AutoML()

settings = {
    "time_budget": 300,  # 5ë¶„
    "metric": "roc_auc",
    "task": "classification",
    "seed": 42,
    "verbose": 1,
    "eval_method": "cv",
    "n_splits": 5,
    "estimator_list": ["lgbm", "xgboost"],
    "custom_hp": {
        "xgboost": {
            "tree_method": {"domain": "hist"},
            "device": {"domain": "cuda:0"},
        },
    }
}

automl.fit(X_train_scaled, y_train, **settings)

print(f"\nìµœì  ëª¨ë¸: {automl.best_estimator}")
print(f"CV ê²€ì¦ ì„±ëŠ¥: {1 - automl.best_loss:.4f}")
print(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\n{automl.best_config}")

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
print(f"\n[3] ë…ë¦½ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€")
y_pred = automl.predict(X_test_scaled)
y_pred_proba = automl.predict_proba(X_test_scaled)[:, 1]

acc = accuracy_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred_proba)

print(f"\nì •í™•ë„: {acc:.4f}")
print(f"ROC-AUC: {auc:.4f}")
print(f"\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_test, y_pred, target_names=['ì •ìƒ', 'ê³µê²©']))

# =========================
# ë‹¤ì¤‘ ë¶„ë¥˜
# =========================
print("\n" + "=" * 80)
print("[4] ë‹¤ì¤‘ ë¶„ë¥˜ ë°ì´í„° ì²˜ë¦¬")
print("=" * 80)

df_train_multi = pd.read_csv('/home/work/skku/iot/Datasets/Farm-Flow_Train_Multiclass.csv')
df_test_multi = pd.read_csv('/home/work/skku/iot/Datasets/Farm-Flow_Test_Multiclass.csv')

# ì „ì²´ ë°ì´í„° í•©ì¹˜ê¸°
df_all_multi = pd.concat([df_train_multi, df_test_multi], ignore_index=True)
print(f"ì „ì²´ ë°ì´í„°: {df_all_multi.shape}")

# ì¤‘ë³µ ì œê±°
feature_cols_multi = [col for col in df_all_multi.columns if col not in ['is_attack', 'traffic']]
df_unique_multi = df_all_multi.drop_duplicates(subset=feature_cols_multi, keep='first')
print(f"ì¤‘ë³µ ì œê±° í›„: {df_unique_multi.shape} ({len(df_unique_multi)/len(df_all_multi)*100:.1f}%)")

# íŠ¹ì§•ê³¼ ë¼ë²¨ ë¶„ë¦¬
X_multi = df_unique_multi[feature_cols_multi].select_dtypes(include=[np.number])
y_multi = df_unique_multi['traffic']

print(f"\në¼ë²¨ ë¶„í¬:\n{y_multi.value_counts()}")

# ìƒˆë¡œìš´ train/test ë¶„í• 
X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(
    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi
)

print(f"\nìƒˆë¡œìš´ ë¶„í• :")
print(f"í›ˆë ¨: {X_train_m.shape[0]}, í…ŒìŠ¤íŠ¸: {X_test_m.shape[0]}")

# ì •ê·œí™”
scaler_m = StandardScaler()
X_train_m_scaled = scaler_m.fit_transform(X_train_m)
X_test_m_scaled = scaler_m.transform(X_test_m)

# AutoML í•™ìŠµ
print(f"\n[5] FLAML AutoML í•™ìŠµ (5ë¶„) - GPU í™œìš© (XGBoost)")
automl_multi = AutoML()

settings_multi = {
    "time_budget": 300,  # 5ë¶„
    "metric": "log_loss",
    "task": "classification",
    "seed": 42,
    "verbose": 1,
    "eval_method": "cv",
    "n_splits": 5,
    "estimator_list": ["lgbm", "xgboost"],
    "custom_hp": {
        "xgboost": {
            "tree_method": {"domain": "hist"},
            "device": {"domain": "cuda:0"},
        },
    }
}

automl_multi.fit(X_train_m_scaled, y_train_m, **settings_multi)

print(f"\nìµœì  ëª¨ë¸: {automl_multi.best_estimator}")
print(f"CV ê²€ì¦ ì„±ëŠ¥: {automl_multi.best_loss:.4f}")

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
print(f"\n[6] ë…ë¦½ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€")
y_pred_m = automl_multi.predict(X_test_m_scaled)

acc_m = accuracy_score(y_test_m, y_pred_m)
print(f"\nì •í™•ë„: {acc_m:.4f}")
print(f"\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_test_m, y_pred_m))

print("\n" + "=" * 80)
print("ì™„ë£Œ!")
print("=" * 80)
print("\nğŸ’¡ ê²°ê³¼ í•´ì„:")
print("- ì´ì „ ê²°ê³¼(ROC-AUC=1.0000)ëŠ” ë°ì´í„° ì¤‘ë³µ(89%)ìœ¼ë¡œ ì¸í•œ ê³¼ì í•©ì´ì—ˆìŠµë‹ˆë‹¤.")
print("- ì¤‘ë³µ ì œê±° í›„ í˜„ì¬ ê²°ê³¼ê°€ ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ì…ë‹ˆë‹¤.")
print("- ë…¼ë¬¸ì—ì„œ ë³´ê³ ëœ ì„±ëŠ¥ê³¼ ë¹„êµí•´ë³´ì„¸ìš”!")
